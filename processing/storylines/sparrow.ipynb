{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import contextily as ctx\n",
    "from matplotlib import pyplot as plt\n",
    "import h3\n",
    "import calendar\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "APIKEY = os.getenv('APIKEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_data = False\n",
    "bbox = (46.4, 6.5, 46.6, 6.8) # Example bounding box for Lausanne area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_dir = os.path.join(\"~\", \"OneDrive - epfl.ch\", \"Research IT\", \"Advanced Services\", \"0042 â€“ Blue City\", \"BlueCityViz\", \"SP04_Waste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lausanne_districts = os.path.join(bc_dir, \"Lausanne Districts.gpkg\")\n",
    "# Open the geopackage file\n",
    "districts_gdf = gpd.read_file(lausanne_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monthly_data(year, month, bbox, filter_name, api_key):\n",
    "    \"\"\"\n",
    "    Fetches data from the Sparrow API for a specific month and filter within a bounding box.\n",
    "    \n",
    "    Args:\n",
    "        year (int): The year (e.g., 2024).\n",
    "        month (int): The month (1-12).\n",
    "        bbox (tuple): A tuple containing (start_lat, start_lon, end_lat, end_lon).\n",
    "        filter_name (str): The specific filter to query (e.g., 'co2').\n",
    "        api_key (str): The API key.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the fetched data.\n",
    "    \"\"\"\n",
    "    url = 'https://api.sparrow.city/get'\n",
    "    headers = {'Accept': 'application/json'}\n",
    "    \n",
    "    # Calculate the last day of the specific month\n",
    "    _, last_day = calendar.monthrange(year, month)\n",
    "    \n",
    "    # Format start and end dates based on API requirements\n",
    "    # Ensure month and day are zero-padded\n",
    "    start_date = f\"{year}-{month:02d}-01T00:00:00\"\n",
    "    end_date = f\"{year}-{month:02d}-{last_day:02d}T23:59:59\"\n",
    "    \n",
    "    start_lat, start_lon, end_lat, end_lon = bbox\n",
    "    \n",
    "    params = {\n",
    "        'filter': filter_name,\n",
    "        'start_date': start_date,\n",
    "        'end_date': end_date,\n",
    "        'start_lat': start_lat,\n",
    "        'start_lon': start_lon,\n",
    "        'end_lat': end_lat,\n",
    "        'end_lon': end_lon,\n",
    "        'api_key': api_key\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching {filter_name} data for {start_date} to {end_date}...\")\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        r.raise_for_status() # Raise error for bad status codes\n",
    "        data = r.json()\n",
    "        \n",
    "        if 'body' in data and data['body']:\n",
    "            df = pd.DataFrame(data['body'])\n",
    "            df['filter'] = filter_name\n",
    "            return df\n",
    "        else:\n",
    "            print(\"No data found or empty body.\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the 12 months of 2025 and combine the entire dataset into a single DataFrame\n",
    "\n",
    "if fetch_data:\n",
    "  all_data = []\n",
    "  for month in range(1, 13):\n",
    "      df_month = get_monthly_data(2024, month, bbox, 'co2', APIKEY)\n",
    "      all_data.append(df_month)\n",
    "      \n",
    "  all_data = pd.concat(all_data, ignore_index=True)\n",
    "  all_data.to_csv('sparrow_co2_2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not fetch_data:\n",
    "    all_data = pd.read_csv('sparrow_co2_2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to geodataframe based on the x and y columns\n",
    "geometry = [Point(xy) for xy in zip(all_data['x'], all_data['y'])]\n",
    "gdf = gpd.GeoDataFrame(all_data, geometry=geometry)\n",
    "gdf.crs = \"EPSG:4326\"\n",
    "# gdf.to_file('data.geojson', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf[gdf['filter'] == 'co2'].to_crs(epsg=3857).plot(figsize=(10, 10), color=\"red\", alpha=0.5)\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.CH)\n",
    "# routes.to_crs(epsg=3857).plot(ax=ax, legend=True, column=\"network\")\n",
    "\n",
    "plt.title(\"Transit Routes in Geneva Area\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hex_bins(gdf, resolution=10):\n",
    "    \"\"\"Create hexagonal bins for a GeoDataFrame.\"\"\"\n",
    "    hex_bins = []\n",
    "    for idx, row in gdf.iterrows():\n",
    "        # Convert coordinates to H3 index\n",
    "        h3_index = h3.latlng_to_cell(row.geometry.x, row.geometry.y, resolution)\n",
    "        hex_bins.append(h3_index)\n",
    "    return hex_bins\n",
    "\n",
    "# Create hex bins for each point in the GeoDataFrame\n",
    "gdf['hex_bin'] = create_hex_bins(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average value of each filter in each hex bin\n",
    "hex_avg = gdf.groupby(['hex_bin', 'filter'])['v'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the geometries\n",
    "h3_geo=gpd.GeoDataFrame(data=hex_avg, geometry = hex_avg.apply(lambda x: Polygon(h3.cell_to_boundary(x.hex_bin)),axis=1),crs=4326)\n",
    "h3_geo['log_v'] = h3_geo['v'].apply(lambda x: np.log(x+1) if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any values 3 IQR below Q1 or above Q3 to further remove outliers\n",
    "Q1 = h3_geo['v'].quantile(0.25)\n",
    "Q3 = h3_geo['v'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "h3_geo = h3_geo[(h3_geo['v'] >= Q1 - 1.5 * IQR) & (h3_geo['v'] <= Q3 + 1.5 * IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=h3_geo[h3_geo['filter'] == 'co2'].to_crs(epsg=3857).plot(column='v',figsize=(10, 10),alpha=0.6)\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.CH)\n",
    "\n",
    "# add colorbar\n",
    "cbar = plt.colorbar(ax.collections[0])\n",
    "cbar.set_label('CO2 Emissions (g CO2 per km)')\n",
    "plt.title(\"Average CO2 Emissions in Lausanne Area (Hexagonal Bins)\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "h3_3857 = h3_geo[h3_geo['filter'] == 'co2'].to_crs(epsg=3857)\n",
    "x = h3_3857.geometry.centroid.x.values\n",
    "y = h3_3857.geometry.centroid.y.values\n",
    "v = h3_3857['v'].values\n",
    "\n",
    "heatmap, xedges, yedges = np.histogram2d(x, y, bins=300, weights=v)\n",
    "counts, _, _ = np.histogram2d(x, y, bins=300)\n",
    "\n",
    "# Avoid division by zero\n",
    "heatmap = np.divide(heatmap, counts, out=np.zeros_like(heatmap), where=counts!=0)\n",
    "\n",
    "sigma = 2\n",
    "heatmap_smooth = gaussian_filter(heatmap, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Add basemap first so it is at the bottom\n",
    "# We need to set the extent of the axes to our data first so contextily knows what to download,\n",
    "# or we can pass the crs and let it handle the current view, but explicitly setting limits is safer.\n",
    "ax.set_xlim(xedges[0], xedges[-1])\n",
    "ax.set_ylim(yedges[0], yedges[-1])\n",
    "\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.CH, zorder = 0)\n",
    "\n",
    "# Add the heatmap with a higher zorder\n",
    "# Transpose is necessary because histogram2d follows x-y convention, fitting image expectation\n",
    "im = ax.imshow(heatmap_smooth.T, origin='lower', cmap='viridis', \n",
    "               extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]], \n",
    "               alpha=0.5, zorder=1)\n",
    "\n",
    "plt.colorbar(im, label='Smoothed CO2 Emissions (Gaussian)')\n",
    "plt.title(\"Gaussian Smoothed Field of CO2 Emissions\")\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Quartiers statistiques shapefile in the local data folder\n",
    "# The file is downloadable from https://viageo.ch/donnee/telecharger/300517\n",
    "quartiers_path = os.path.join(\".\", \"data\", \"Quartiers statistiques.shp\")\n",
    "quartiers_gdf = gpd.read_file(quartiers_path).to_crs(epsg=3857)\n",
    "quartiers_gdf = quartiers_gdf[quartiers_gdf['NOMQUARTIE'] != \"Zones foraines\"]\n",
    "quartiers_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "hexagons = quartiers_gdf.to_crs(epsg=4326).geometry.apply(lambda x: h3.geo_to_cells(x, res=11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_to_shapely(cell):\n",
    "    coords = h3.cell_to_boundary(cell)\n",
    "    flipped = tuple(coord[::-1] for coord in coords)\n",
    "    return Polygon(flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a left join on the exploded hexagons, renaming the geometry column as hex_hash\n",
    "exploded_hexagons = hexagons.explode().apply(lambda x: cell_to_shapely(x))\n",
    "\n",
    "quartiers_hex = quartiers_gdf.merge(exploded_hexagons, left_index=True, right_index=True, how='left')\n",
    "quartiers_hex = gpd.GeoDataFrame(\n",
    "    data = quartiers_hex.drop(columns=['geometry_x', 'geometry_y']),\n",
    "    geometry = quartiers_hex['geometry_y'],\n",
    "    crs = 4326\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only unique hexagons, and sample the co2 values for each hexagon at its centroid\n",
    "hex_gdf = quartiers_hex.drop_duplicates(subset='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_heatmap(geometry):\n",
    "    \"\"\"\n",
    "    Samples the heatmap value at the geometry's coordinates.\n",
    "    Assumes geometry is in the same CRS (EPSG:3857) as xedges/yedges.\n",
    "    \"\"\"\n",
    "    # Get coordinates\n",
    "    px = geometry.x\n",
    "    py = geometry.y\n",
    "    \n",
    "    # Check if point is inside the heatmap bounds\n",
    "    if px < xedges[0] or px > xedges[-1] or py < yedges[0] or py > yedges[-1]:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate bin indices\n",
    "    # (val - min) / (max - min) * num_bins\n",
    "    x_idx = int((px - xedges[0]) / (xedges[-1] - xedges[0]) * (len(xedges) - 1))\n",
    "    y_idx = int((py - yedges[0]) / (yedges[-1] - yedges[0]) * (len(yedges) - 1))\n",
    "\n",
    "    # Clip indices to ensure they are within bounds (handle edge cases)\n",
    "    x_idx = min(max(x_idx, 0), heatmap_smooth.shape[0] - 1)\n",
    "    y_idx = min(max(y_idx, 0), heatmap_smooth.shape[1] - 1)\n",
    "\n",
    "    # Return value from the smoothed heatmap\n",
    "    # Note: heatmap_smooth shape is (x_bins, y_bins) from histogram2d\n",
    "    return heatmap_smooth[x_idx, y_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_gdf['co2_smooth'] = hex_gdf.to_crs(epsg=3857).geometry.centroid.apply(sample_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hex_gdf.to_crs(epsg=3857).plot(column='co2_smooth', figsize=(10, 10), legend=True)\n",
    "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.CH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bluecity-viz-processing (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
